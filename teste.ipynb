{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 100, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def inv_sigmoid(x):\n",
    "    return np.log(y/(1-y))\n",
    "%matplotlib inline\n",
    "path = '_data/abstract_art/Abstract_gallery/Abstract_gallery'\n",
    "os.getcwd()\n",
    "img_list = os.listdir(path)\n",
    "def access_images(img_list,path,length):\n",
    "    pixels = []\n",
    "    imgs = []\n",
    "    for i in range(length):\n",
    "        img = Image.open(path+'\\\\'+img_list[i],'r')\n",
    "        basewidth = 100\n",
    "        img = img.resize((basewidth,basewidth), Image.ANTIALIAS)\n",
    "        pix = np.array(img.getdata())\n",
    "        pixels.append(pix.reshape(100,100,3))\n",
    "        imgs.append(img)\n",
    "    return np.array(pixels),imgs\n",
    "def show_image(pix_list):\n",
    "    array = np.array(pix_list.reshape(100,100,3), dtype=np.uint8)\n",
    "    new_image = Image.fromarray(array)\n",
    "    new_image.show()\n",
    "pixels,imgs = access_images(img_list,path,1000)\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape = (100,100,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 25 * 25\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((25, 25, 128)))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(3, (7,7) , padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
    "    g_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=10):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    print(dataset.shape[0])\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "        if (i+1) % 10 == 0:\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[239 238 236]\n",
      "   [243 242 240]\n",
      "   [241 241 239]\n",
      "   ...\n",
      "   [239 237 238]\n",
      "   [239 237 238]\n",
      "   [239 237 238]]\n",
      "\n",
      "  [[238 236 234]\n",
      "   [220 218 216]\n",
      "   [221 219 218]\n",
      "   ...\n",
      "   [161 160 160]\n",
      "   [175 174 175]\n",
      "   [239 237 238]]\n",
      "\n",
      "  [[225 222 220]\n",
      "   [143 140 139]\n",
      "   [161 159 157]\n",
      "   ...\n",
      "   [160 160 160]\n",
      "   [176 176 177]\n",
      "   [240 238 240]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[247 246 244]\n",
      "   [219 218 216]\n",
      "   [140 139 137]\n",
      "   ...\n",
      "   [139 139 139]\n",
      "   [161 161 161]\n",
      "   [211 210 210]]\n",
      "\n",
      "  [[248 247 245]\n",
      "   [214 213 211]\n",
      "   [109 108 106]\n",
      "   ...\n",
      "   [163 163 163]\n",
      "   [169 169 169]\n",
      "   [209 208 207]]\n",
      "\n",
      "  [[243 243 241]\n",
      "   [232 231 229]\n",
      "   [189 189 187]\n",
      "   ...\n",
      "   [244 244 244]\n",
      "   [240 240 240]\n",
      "   [239 237 238]]]\n",
      "\n",
      "\n",
      " [[[248 248 246]\n",
      "   [247 248 245]\n",
      "   [249 249 247]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [249 249 246]]\n",
      "\n",
      "  [[248 248 246]\n",
      "   [248 248 246]\n",
      "   [237 237 235]\n",
      "   ...\n",
      "   [107 105 103]\n",
      "   [170 168 167]\n",
      "   [253 253 252]]\n",
      "\n",
      "  [[245 245 244]\n",
      "   [255 255 255]\n",
      "   [146 144 139]\n",
      "   ...\n",
      "   [ 22  21  19]\n",
      "   [100  98  96]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[251 251 249]\n",
      "   [254 254 252]\n",
      "   [243 243 240]\n",
      "   ...\n",
      "   [ 98  95  91]\n",
      "   [ 97  90  84]\n",
      "   [206 204 200]]\n",
      "\n",
      "  [[252 252 250]\n",
      "   [252 252 250]\n",
      "   [251 251 249]\n",
      "   ...\n",
      "   [242 242 240]\n",
      "   [244 243 242]\n",
      "   [251 251 249]]\n",
      "\n",
      "  [[253 253 251]\n",
      "   [252 252 250]\n",
      "   [252 252 250]\n",
      "   ...\n",
      "   [255 255 253]\n",
      "   [255 255 253]\n",
      "   [253 253 251]]]\n",
      "\n",
      "\n",
      " [[[ 73  73  73]\n",
      "   [ 33  33  33]\n",
      "   [ 41  41  41]\n",
      "   ...\n",
      "   [ 99  99  99]\n",
      "   [ 96  96  96]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[ 71  71  71]\n",
      "   [ 32  32  32]\n",
      "   [ 45  45  45]\n",
      "   ...\n",
      "   [ 67  67  67]\n",
      "   [ 68  68  68]\n",
      "   [ 52  52  52]]\n",
      "\n",
      "  [[ 66  66  66]\n",
      "   [ 28  28  28]\n",
      "   [ 31  31  31]\n",
      "   ...\n",
      "   [ 73  73  73]\n",
      "   [ 67  67  67]\n",
      "   [ 59  59  59]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 27  27  27]\n",
      "   [ 24  24  24]\n",
      "   [ 24  24  24]\n",
      "   ...\n",
      "   [ 15  15  15]\n",
      "   [ 18  18  18]\n",
      "   [ 22  22  22]]\n",
      "\n",
      "  [[ 30  30  30]\n",
      "   [ 22  22  22]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [ 13  13  13]\n",
      "   [ 20  20  20]\n",
      "   [ 21  21  21]]\n",
      "\n",
      "  [[ 30  30  30]\n",
      "   [ 33  33  33]\n",
      "   [ 31  31  31]\n",
      "   ...\n",
      "   [ 15  15  15]\n",
      "   [ 15  15  15]\n",
      "   [ 18  18  18]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 32  32  32]\n",
      "   [ 15  15  15]\n",
      "   [ 16  16  16]\n",
      "   ...\n",
      "   [ 95  95  95]\n",
      "   [ 77  77  77]\n",
      "   [ 42  42  42]]\n",
      "\n",
      "  [[ 49  49  49]\n",
      "   [ 76  76  76]\n",
      "   [ 94  94  94]\n",
      "   ...\n",
      "   [150 150 150]\n",
      "   [135 135 135]\n",
      "   [ 72  72  72]]\n",
      "\n",
      "  [[ 63  63  63]\n",
      "   [ 76  76  76]\n",
      "   [103 103 103]\n",
      "   ...\n",
      "   [154 154 154]\n",
      "   [152 152 152]\n",
      "   [110 110 110]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[178 178 178]\n",
      "   [138 138 138]\n",
      "   [125 125 125]\n",
      "   ...\n",
      "   [125 125 125]\n",
      "   [156 156 156]\n",
      "   [130 130 130]]\n",
      "\n",
      "  [[176 176 176]\n",
      "   [156 156 156]\n",
      "   [138 138 138]\n",
      "   ...\n",
      "   [139 139 139]\n",
      "   [162 162 162]\n",
      "   [145 145 145]]\n",
      "\n",
      "  [[170 170 170]\n",
      "   [161 161 161]\n",
      "   [158 158 158]\n",
      "   ...\n",
      "   [151 151 151]\n",
      "   [162 162 162]\n",
      "   [151 151 151]]]\n",
      "\n",
      "\n",
      " [[[  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0   0   1]\n",
      "   [ 28  27  29]\n",
      "   [160 162 134]\n",
      "   ...\n",
      "   [ 71  73  65]\n",
      "   [  0   0   0]\n",
      "   [  3   2   5]]\n",
      "\n",
      "  [[  0   1   2]\n",
      "   [ 19  20  25]\n",
      "   [112 114 100]\n",
      "   ...\n",
      "   [ 23  24  20]\n",
      "   [  0   0   0]\n",
      "   [  1   1   3]]\n",
      "\n",
      "  [[  1   1   2]\n",
      "   [  0   0   1]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]\n",
      "\n",
      "\n",
      " [[[  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   ...\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]]\n",
      "\n",
      "  [[  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   ...\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]]\n",
      "\n",
      "  [[  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   ...\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   ...\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]]\n",
      "\n",
      "  [[  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   ...\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]]\n",
      "\n",
      "  [[  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   ...\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]\n",
      "   [  4   3   8]]]]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(pixels.shape)\n",
    "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)\n",
    "print(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[174.82292 , 199.88094 , 196.02802 ],\n",
       "         [206.42442 , 207.28098 , 196.26529 ],\n",
       "         [199.75482 , 207.49063 , 211.5151  ],\n",
       "         ...,\n",
       "         [218.0264  , 200.3931  , 181.9071  ],\n",
       "         [201.23134 , 187.64282 , 175.73567 ],\n",
       "         [210.57559 , 202.58563 , 174.3765  ]],\n",
       "\n",
       "        [[189.60954 , 205.35918 , 212.02261 ],\n",
       "         [211.57349 , 225.63838 , 236.71117 ],\n",
       "         [207.59937 , 206.53273 , 232.3247  ],\n",
       "         ...,\n",
       "         [209.15627 , 192.00897 , 162.32086 ],\n",
       "         [206.08873 , 186.90652 , 179.11487 ],\n",
       "         [204.78563 , 194.2931  , 167.63411 ]],\n",
       "\n",
       "        [[201.33925 , 209.45268 , 219.81802 ],\n",
       "         [231.40045 , 208.8106  , 226.85095 ],\n",
       "         [208.28331 , 212.7565  , 232.44312 ],\n",
       "         ...,\n",
       "         [229.878   , 181.72208 , 182.65158 ],\n",
       "         [218.38205 , 197.1462  , 177.32198 ],\n",
       "         [216.1217  , 188.1749  , 166.7609  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[176.03423 , 116.51344 ,  74.16578 ],\n",
       "         [134.41982 , 108.004585,  49.421974],\n",
       "         [142.27669 , 107.761894,  73.77966 ],\n",
       "         ...,\n",
       "         [145.28716 , 145.11505 , 105.87341 ],\n",
       "         [161.2583  , 150.55315 , 133.21483 ],\n",
       "         [168.26515 , 154.03758 , 129.77757 ]],\n",
       "\n",
       "        [[175.72249 , 124.322754, 103.21183 ],\n",
       "         [154.06485 , 128.33986 ,  89.831154],\n",
       "         [178.91391 , 126.27792 ,  97.23296 ],\n",
       "         ...,\n",
       "         [193.21426 , 188.97437 , 166.38321 ],\n",
       "         [185.95218 , 177.61699 , 145.51538 ],\n",
       "         [180.56644 , 173.26257 , 157.7399  ]],\n",
       "\n",
       "        [[187.9924  , 157.8082  , 132.65129 ],\n",
       "         [163.54736 , 157.48087 , 111.84194 ],\n",
       "         [185.92433 , 155.83742 , 130.68205 ],\n",
       "         ...,\n",
       "         [233.2831  , 221.98729 , 202.3464  ],\n",
       "         [219.9251  , 207.86244 , 205.21498 ],\n",
       "         [217.51291 , 200.5016  , 190.50677 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "model = g_model\n",
    "latent_points = generate_latent_points(300,1)\n",
    "X = model.predict(latent_points)\n",
    "array = np.array(X.reshape(100,100,3), dtype=np.uint8)\n",
    "new_image = Image.fromarray(array)\n",
    "new_image.show()\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "841b1d841351cf74e946f307381221a2bfba6f1d408580d3b54b4f617b3016ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
